{
  "model": {
    "type": "florence2",
    "pad_token_id": 1,
    "eos_token_id": 2,
    "bos_token_id": 0,
    "decoder_start_token_id": 2,
    "vocab_size": 51289,
    "context_length": 768,
    "encoder_decoder_init": {
      "filename": "encoder_model.onnx"
    },
    "embedding": {
      "filename": "embed_tokens.onnx",
      "inputs": {
        "input_ids": "input_ids"
      }
    },
    "vision": {
      "filename": "vision_encoder_with_preprocessing.onnx",
      "inputs": {
        "pixel_values": "image"
      },
      "outputs": {
        "visual_features": "image_features"
      }
    },
    "decoder": {
      "filename": "decoder_model_merged.onnx",
      "hidden_size": 768,
      "num_hidden_layers": 6,
      "num_key_value_heads": 12,
      "head_size": 64,
      "inputs": {
        "attention_mask": "encoder_attention_mask",
        "past_key_names": "past_key_values.%d.decoder.key",
        "past_value_names": "past_key_values.%d.decoder.value",
        "cross_past_key_names": "past_key_values.%d.encoder.key",
        "cross_past_value_names": "past_key_values.%d.encoder.value"
      },
      "outputs": {
        "logits": "logits",
        "present_key_names": "present.%d.decoder.key",
        "present_value_names": "present.%d.decoder.value",
        "cross_present_key_names": "present.%d.encoder.key",
        "cross_present_value_names": "present.%d.encoder.value"
      }
    }
  },
  "search": {
    "do_sample": true,
    "early_stopping": true,
    "diversity_penalty": 0.0,
    "min_length": 0,
    "max_length": 50,
    "num_beams": 3,
    "top_k": 1,
    "top_p": 1.0,
    "temperature": 1.0,
    "repetition_penalty": 1.0,
    "past_present_share_buffer": false,
    "num_return_sequences": 1
  }
}